\section{Scheduling Complexity}
\label{sec:scheduling}

We may notice that operational semantics described in the previous section can be used to calculate the number of elementary scheduling steps.
In this section, we define a specific value that estimates the scheduling time and give some equations to calculate this value for a given \emph{semantic
state}. However, our ultimate goal is to provide a way to deduce the complexity factor recursively for a given query. This problem will be addressed in
Section~\ref{sec:symbolic}, which will make use of recurrent equations presented here.

We also restrict our considerations only by the case when the evaluation of a goal in question terminates. Indeed,
if the search diverges, no reasonable complexity estimation for the time of the whole search can be given. A much more interesting question would be
the complexity estimation for coming up with some \emph{specific} answer; however for now this problem seems to be too hard to
tackle.

Our first idea is to take the number of states $d\,(s)$ in the \emph{finite} trace for a given state $s$:

\[ d\,(s) \; \eqdef \; | \trs{s} |  \]

However, it turns out, that this value alone is not enough to provide an accurate scheduling complexity estimation. The reason is that some
elementary steps in the semantics are not elementary in existing implementations. Namely, a careful analysis of the semantics discovers that
it involves navigation to the leftmost leaf of the state, which in implementations corresponds to a number of
steps, proportional to the length of the leftmost branch of the state in question. Here we provide an \emph{ad-hoc} definition for this value, $t\,(s)$, which we call the
\emph{scheduling factor}:

\[
t\,(s) \eqdef \sum\limits_{s_i \in \trs{s}} lh\,(s_i) 
\]

where

\[
\begin{array}{rcl}
 lh\,(\taskst{g}{e})  &\eqdef& 1 \\
 lh\,(s_1 \oplus s_2) &\eqdef& lh\,(s_1) + 1 \\
 lh\,(s \otimes g)    &\eqdef& lh\,(s) + 1 \\
\end{array}
\]


The following lemma provides a fundamental relation between these two estimations of the scheduling complexity:

\begin{lemma}
  For any state $s$

  \[
  d\,(s) \le t\,(s) \le d^2\,(s)
  \]
  
\end{lemma}

Our next goal is to come up with the equations which relate the scheduling complexity of states with the scheduling complexity of their
(immediate) substates. We take scheduling factor $t\,(s)$ as a value that determines the scheduling complexity $T_s$, but we will also need to calculate $d\,(s)$ as it will be used in the equations for $t\,(s)$. 

The following lemma, obvious from the definitions, will be enough to deal with a basic (leaf state) case:

\begin{lemma}
  If

  \[\taskst{g}{e} \xrightarrow{\circ} s^\prime\]

  or

  \[\taskst{g}{e} \xrightarrow{a} s^\prime\]

  then

  \[d\,(\taskst{g}{e}) = d\,(s^\prime) + 1\]

  and

  \[t\,(\taskst{g}{e}) = t\,(s^\prime) + 1\]
\end{lemma}

%In $\oplus$-states the substates are evaluated separately, one step at a time for each substate,
%so the total number of semantic steps is just a sum.
%However, for the scheduling factor, there is an extra summand since the heights of the states in
%the trace become bigger (by one additional $\oplus$-node on the top).
%This additional node exists in the trace until one of the substates is evaluated completely, so the
%scheduling factor is increased by the number of steps before such an event.
%So we have the following lemma.

In state of the form $s_1 \oplus s_2$ the substates are evaluated separately, one step at a time for
each substate, so the total number of semantic steps is just a sum.
However, for the scheduling factor, there is an extra summand $\costdisj{s_1}{s_2}$ since the
heights of the states in the trace are increased by one additional $\oplus$-node on the top.
This additional node exists in the trace until one of the substates is evaluated completely,
so the scheduling factor is increased by the number of steps before such event.
So we have the following lemma.

\begin{lemma}
\label{lem:sum_estimation}
For any two states $s_1$ and $s_2$

\[
\begin{array}{rcl}
  d\,(s_1 \oplus s_2) &=& d\,(s_1) + d\,(s_2) \\

%  t\,(s_1 \oplus s_2) &=& t\,(s_1) + t\,(s_2) + \min\,\{2\cdot d\,(s_1) - 1, 2\cdot d\,(s_2)\}
    t\,(s_1 \oplus s_2) &=& t\,(s_1) + t\,(s_2) + \costdisj{s_1}{s_2}
\end{array}
\]

where

\[ \costdisj{s_1}{s_2} = \min\,\{2\cdot d\,(s_1) - 1, 2\cdot d\,(s_2)\} \] 

\end{lemma}

For states of the form $s \otimes g$ the reasoning is the same, but the result is more complicated.
In $\otimes$-state the left substate is evaluated until an answer is found, which is then taken as
\emph{an environment} for evaluation of the right subgoal.
Thus, in the equations for $\otimes$-states we sum evaluation time of the second goal for all
the answers generated for the first substate.
The tasks of evaluating the right subgoal in different environments are added to the
evaluation of the left substate by creation of an $\oplus$-state, so for scheduling factor there is
an additional summand $\costdisj{\taskst{g}{a_i}}{s'_i}$ for each answer with $s'_i$ being the state
after dicovering the given answer.
There is also an extra summand $\costconj{s}{g}$ to the scheduling factor because of the
$\otimes$-node that increases the height in the trace, analogous to the one caused by
$\oplus$-nodes.
We can notice that $\otimes$-node is always placed immediately over the left substate so this
addition is exactly the number of steps for the left substate.
Therefore the resulting equations for $\otimes$-states are as follows.

\begin{lemma}
For any state $s$ and any goal $g$

\[
\begin{array}{rcl}
d\,(s \otimes g)  &=&  d\,(s) + \displaystyle\sum\limits_{a_i \in \tra{s}} d\,(\taskst{g}{a_i}) \\

 t\,(s \otimes g)  &=&  t\,(s) + (\displaystyle\sum\limits_{a_i \in \tra{s}} (t\,(\taskst{g}{a_i}) + \costdisj{\taskst{g}{a_i}}{(s'_i \otimes g)})) + \costconj{s}{g}
\end{array}
\]

where 

\begin{align*}
& \costdisj{s_1}{s_2} = \min\,\{2\cdot d\,(s_1) - 1, 2\cdot d\,(s_2)\} \\
& \costconj{s}{g} = d\,(s) \\
& s'_i \text{is the next state in the trace for s after the transition labeled with the answer $a_i$} \\
\end{align*}
\end{lemma}

After unfolding the auxiliary definitions the last equation is too cumbersome to use directly,
so we will use some approximation of it instead.
One option is to go with the first argument of ``$\min$'' in $\costdisj{\taskst{g}{a_i}}{s'_i}$.
It should be a good approximation in the case when there are several answers passed to the second
goal and for none of them the number of steps surpasses the \emph{overall} number of steps for all
other answers (the second argument of ``$\min$'' will include the sum for the rest of the answers).

\begin{corollary}
\label{lem:prod_estimation_multiple_answers}
For any state $s$ and any goal $g$
\[ t\,(s \otimes g) \le t\,(s) + d\,(s) + \displaystyle\sum\limits_{a_i \in \tra{s}} (t\,(\taskst{g}{a_i}) + 2\cdot d\,(\taskst{g}{a_i}) \]
\end{corollary}

In the case when there is only one answer, however, we should rather go with the second argument of ``$\min$''. 

In this case the number of steps $d(s'_1 \otimes g)$ is equal to the number of steps $d(s'_1)$
since no more aswers are produced, and we can approximate it by the length $d(s)$ of the whole
trace for $s$. 

\begin{corollary}
\label{lem:prod_estimation_single_answer}
  For any state $s$ and any goal $g$, if $\tra{s} = \{a\}$, then
  
\[ t\,(s \otimes g) \le t\,(s) + 3\cdot d\,(s) + t\,(\taskst{g}{a}) \]
\end{corollary}

Finally, since we estimate only up to a multiplicative constant (in particular, it does not matter by what constants we multiply values of $d\,(\cdot)$ when calculating
the scheduling factor) we can derive from these results two compact scheduling time approximations for goals in the form of sequences of disjuncts/conjuncts.
These two approximations work regardless of the associativity/grouping of subformulas; thus a certain constant $c_k$, depending only on $k$, comes in.

For conjunctions, we have the following one.

\begin{lemma}
\label{lem:conjunction_metrics_calc}

Let $g = g_1 \land \dots \land g_k$ and let $A_i$ be a set of all answers that are passed to $g_i$ at some stage starting from some initial environment $e_0$

\[
\begin{array}{rcl}
A_1 &=& \{ e_0 \} \\
A_{i + 1} & = & \bigcup\limits_{a \in A_i} \tra{\taskst{g_i}{a}} 
\end{array}
\]

Then

\[
\begin{array}{rcl}
d\,(\taskst{g}{e}) &=& \displaystyle\sum\limits_{1 \le i \le k} \;\; \displaystyle\sum\limits_{a \in A_i} d\,(\taskst{g_i}{a}) \\
t\,(\taskst{g}{e}) &\le& \displaystyle\sum\limits_{1 \le i \le k} \;\; \displaystyle\sum\limits_{a \in A_i} t\,(\taskst{g_i}{a}) + c_k \cdot \displaystyle\sum\limits_{1 \le i \le k} \;\; \displaystyle\sum\limits_{a \in A_i} d\,(\taskst{g_i}{a}), \\
\end{array}
\]

In the case when all $A_i$ contain only one answer

\[
t\,(\taskst{g}{e}) \le \displaystyle\sum\limits_{1 \le i \le k} \;\; \displaystyle\sum\limits_{a \in A_i} t\,(\taskst{g_i}{a}) + c_k \cdot \displaystyle \sum\limits_{1 \le i \le k - 1} \;\; \displaystyle\sum\limits_{a \in A_i} d\,(\taskst{g_i}{a})
\]

\end{lemma}

When applying the estimation from corollary~\ref{lem:prod_estimation_multiple_answers} we have an extra summand in the form of the number of steps (multiplied by some constant) for all conjuncts.
The only exception is the case when every conjunct produces no more than one answer, then we can use the corollary~\ref{lem:prod_estimation_single_answer} everywhere instead and drop out the
additional number of steps for the last conjunct. Besides that, a constant number of steps is required to turn each conjunction into a $\otimes$-state, but we may integrate this extra constant into $c_k$.

For disjunctions, the lemma is the following one.

\begin{lemma}
\label{lem:disjunction_metrics_calc}

Let $g = g_1 \lor \dots \lor g_k$ and $1 \le l \le k$; then

\[
\renewcommand{\arraystretch}{1.5}
\begin{array}{rcl}
  d\,(\taskst{g}{e}) &\le& \displaystyle\sum\limits_{1 \le i \le k} d\,(\taskst{g_i}{e}) \\
  t\,(\taskst{g}{e}) &\le& \displaystyle\sum\limits_{1 \le i \le k} t\,(\taskst{g_i}{e}) + c_k\cdot \displaystyle\sum\limits_{\renewcommand{\arraystretch}{1}\begin{array}{c}1 \le i \le k \\ i \ne l\end{array}} d\,(\taskst{g_i}{e}).
\end{array}
\]

\end{lemma}

Roughly speaking, if we have a disjunct $g_m$ with a number of steps larger than all the steps for other disjuncts combined, then when applying lemma~\ref{lem:sum_estimation} we again will have an
extra summand in the form of the number of steps for all disjuncts except for the $g_m$ (it will always be the largest argument of ``$\min$''). But if we can drop out the \emph{largest}
the number of steps among disjuncts, we can also drop out any other instead, that's where arbitrary $l$ comes from. The case when there is no such $g_m$ has to be considered separately; it is simpler
since then all the numbers of steps are the same up to a multiplicative constant.
