\section{Complexity Analysis via Symbolic Execution Schemes}
\label{sec:symbolic}

We build schemes in the following form.

\[
\renewcommand{\arraystretch}{3}
\begin{array}{ccm{0.5cm}m{3cm}m{4cm}m{4cm}}
  \schemewithvset{\mathfrak{S}}{V} & = && \schemenode{$\unigoal{\mathcal{T}_\mathcal{A}}{\mathcal{T}_\mathcal{A}}$} & \schemenode{$\invokegoal{R^k}{\mathcal{T}_\mathcal{A}}{\mathcal{T}_\mathcal{A}}$} 
                                       & \multirow{2}{*}{\schemefork{$\schemewithvset{\mathfrak{S}}{V}$}{$\schemewithvset{\mathfrak{S}}{V}$}} \\
                                   &   && \schemesarrow{$\unigoal{\mathcal{T}_\mathcal{A}}{\mathcal{T}_\mathcal{A}}$}{$\{\mathcal{A}=\mathcal{T}_\mathcal{A}\}$}{$\schemewithvset{\mathfrak{S}}{U}$}
                                       & \schemedarrow{$\invokegoal{R^k}{\mathcal{T}_\mathcal{A}}{\mathcal{T}_\mathcal{A}}$}{$(\mathcal{T}_\mathcal{A}, \dots, \mathcal{T}_\mathcal{A}) \in \sembr{R^k}$}{$\schemewithvset{\mathfrak{S}}{U}$}
                                       & 
\end{array}
\]

For building schemes we need the two following notions.

\[
\upd{U}{\delta} = \begin{cases}
                           U & \quad\forall x \in U : FV\,(\delta\,(x)) \subset U \\
                           \upd{U \cup \displaystyle\bigcup\limits_{x \in U} FV\,(\delta\,(x))}{\delta} & \quad\mbox{otherwise}
                          \end{cases}
\]

\[ \constr{\delta}{U} = \{ x = \delta\,(x) \mid x \in U \cap \mathcal{D}om\,(\delta) \} \]

The rules for building schemes have the following form:

\[
\schemetrans{g}{\Gamma}{\sigma}{n}{V}{\schemewithvset{\mathfrak{S}}{V}}
\]

% TODO: an explanation is required here or elsewhere
where $\Gamma$ is a list of goals, $\sigma$ and $n$ are current substitution and free variable counter respectively, $V$~--- a set of ground variables, $g$ --- current 
goal. Scheme formation rules are shown in the Fig.~\ref{fig:scheme_formation}.

\begin{figure}[t]  
%\renewcommand{\arraystretch}{2}
  \[
\begin{array}{cr}
  \onepremrule
		{  \schemetrans{g_1}{g_2 : \Gamma}{\sigma}{n}{V}{\schemewithvset{\mathfrak{S}}{V}}  } 
		{  \schemetrans{\conjgoal{g_1}{g_2}}{\Gamma}{\sigma}{n}{V}{ \schemewithvset{\mathfrak{S}}{V} }  } & \ruleno{Conj$_\mathfrak S$}
		\\
 \onepremrule
		{  \schemetrans{\substitute{g}{\alpha_n}{x}}{\Gamma}{\sigma}{n + 1}{V}{\schemewithvset{\mathfrak{S}}{V}}  }
		{  \schemetrans{\freshgoal{x}{g}}{\Gamma}{\sigma}{n}{V}{ \schemewithvset{\mathfrak{S}}{V} }  } & \ruleno{Fresh$_\mathfrak S$}\\
                
  % \multicolumn{3}{c}{
  \twopremrule
		{  \schemetrans{g_1}{\Gamma}{\sigma}{n}{V}{\schemewithvset{\mathfrak{S_1}}{V}}  }
		{  \schemetrans{g_2}{\Gamma}{\sigma}{n}{V}{\schemewithvset{\mathfrak{S_2}}{V}}  }
		{  \schemetrans{\disjgoal{g_1}{g_2}}{\Gamma}{\sigma}{n}{V}{\parbox[m]{2cm}{ \schemefork{$\schemewithvset{\mathfrak{S_1}}{V}$}{$\schemewithvset{\mathfrak{S_2}}{V}$}} }  } & \ruleno{Disj$_\mathfrak S$}\\ 
		
 %\multicolumn{3}{c}{
  \schemetrans{\unigoal{t_1}{t_2}}{\epsilon}{\sigma}{n}{V}{\parbox[m]{2cm}{\schemenode{$\unigoal{t_1 \sigma}{t_2 \sigma}$}}}& \ruleno{UnifyLeaf$_\mathfrak S$}\\

 %\multicolumn{3}{c}{
 \schemetrans{\invokegoal{R^k}{t_1}{t_k}}{\epsilon}{\sigma}{n}{V}{\parbox[m]{2cm}{\schemenode{$\invokegoal{R^k}{t_1 \sigma}{t_k \sigma}$}}}& \ruleno{InvokeLeaf$_\mathfrak S$}\\ 
		
 %\multicolumn{3}{c}{
  \onepremrule
		{  \nexists mgu\,(t_1 \sigma, t_2 \sigma)  }
		{  \schemetrans{\unigoal{t_1}{t_2}}{g : \Gamma}{\sigma}{n}{V}{\parbox[m]{2cm}{\schemenode{$\unigoal{t_1 \sigma}{t_2 \sigma}$}}} }& \ruleno{UnifyFail$_\mathfrak S$}\\

 %\multicolumn{3}{c}{
  \threepremrule
		{  mgu\,(t_1 \sigma, t_2 \sigma) = \delta  }
		{  U = \upd{V}{\delta}  }
		{  \schemetrans{g}{\Gamma}{\sigma \delta}{n}{U}{\schemewithvset{\mathfrak{S}}{U}}  }
		{  \schemetrans{\unigoal{t_1}{t_2}}{g : \Gamma}{\sigma}{n}{V}{\parbox[m]{2cm}{\schemesarrow{$\unigoal{t_1 \sigma}{t_2 \sigma}$}{$\constr{\delta}{U}$}{$\schemewithvset{\mathfrak{S}}{U}$}} }   } & \ruleno{UnifySuccess$_\mathfrak S$}\\
		
 %\multicolumn{3}{c}{
  \twopremrule
		{  \mbox{\phantom{XXXXXX}} U =  V \cup \displaystyle\bigcup\limits_{i} FV\,(t_i \sigma) }
		{  \schemetrans{g}{\Gamma}{\sigma}{n}{U}{\schemewithvset{\mathfrak{S}}{U}} \mbox{\phantom{XXXXXX}} }
		{  \schemetrans{\invokegoal{R^k}{t_1}{t_k}}{g : \Gamma}{\sigma}{n}{V}{ \parbox[m]{2cm}{\schemedarrow{$\invokegoal{R^k}{t_1 \sigma}{t_k \sigma}$}{$ (t_1 \sigma, \dots, t_k \sigma) \in \sembr{R^k} $}{$\schemewithvset{\mathfrak{S}}{U}$}} }   } & \ruleno{Invoke$_\mathfrak S$}
 \end{array}
\]
\caption{Scheme Formation Rules}
\label{fig:scheme_formation}
\end{figure}

              
It is important to note that both our time measures are ``stable'' w.r.t. renaming of logical variables and change of counter of fresh logical variables (as long as it stays adequate).

\FloatBarrier

\begin{replemma}{lem:measures_changing_env}

  Suppose

  \[ FV\,(g) \cup \Dom\,(\sigma) \cup \VRan\,(\sigma) \subseteq \{ \alpha_1\dots\alpha_n \} \]
  
  and

  \[ FV\,(g^\prime) \cup \Dom\,(\sigma^\prime) \cup \VRan\,(\sigma^\prime) \subseteq \{ \alpha_1\dots \alpha_{n^\prime} \} \]

  and there is a bijective substitution

  \[\pi \colon FV\,(g \sigma) \to FV\,(g^\prime \sigma^\prime)\]

  such that

  \[ g \sigma \pi = g^\prime \sigma^\prime \]

  Then \[ d\,(\taskst{g}{\mkenv{\sigma}{n}}) = d\,(\taskst{g^\prime}{\mkenv{\sigma^\prime}{n^\prime}}) \] and \[ t\,(\taskst{g}{\mkenv{\sigma}{n}}) = t\,(\taskst{g}{\mkenv{\sigma}{n}}) \] 

\end{replemma}

So the following definition will be useful to construct a leaf-state representative for an arbitrary goal.

\begin{definition} Let $g$ be a goal. An initial state for $g$ is


  \[
   init\,(g)=\taskst{g}{(\varepsilon, \ninit\,(g))}
  \]

  where
  
  \[ n_{init}\,(g) = \min\, \{ n \mid FV\,(g) \subseteq \{ \alpha_1\dots\alpha_n \} \} \]
\end{definition}
		
The extracted approximations will use the following definition.

\begin{definition}
  Suppose

  \[V \subset U \subset \mathcal{A}\]

  and

  \[\rho \colon V \to \mathcal{T}_{\emptyset}\]

  and

  \[\rho^\prime \colon U \to \mathcal{T}_{\emptyset}\]

  We say that $\rho^\prime$ extends $\rho$ (denotation: $ \rho^\prime \succ \rho$) if
  
\[ \forall x \in V \,:\, \rho^\prime\,(x) = \rho\,(x) \]
\end{definition}

Here are the traversals of scheme that will be used for approximations. For a scheme $\schemewithvset{\mathfrak{S}}{V}$ it is a function from representative function $\rho \colon V \to \grterms$ to natural numbers (for $\mathcal{D}$ and $\mathcal{T}$) or to sets of leaf-states (for $\mathcal{L}$).

\begin{figure}[t]
\[
\begin{array}{rclcl}
 \mathcal{\nicefrac{D}{T}}\,(&\parbox[m]{1.3cm}{\schemenode{$\unigoal{t_2}{t_2}$}}&)(\rho) &=& 1  \\

 \mathcal{\nicefrac{D}{T}}\,(&\parbox[m]{2.5cm}{\schemenode{$\invokegoal{R^k}{t_1}{t_k}$}}&)(\rho) &=& \nicefrac{d}{t}\,(\taskst{\invokegoal{R^k}{t_1 \rho}{t_k \rho}}{e_{init}}) \\

 \mathcal{\nicefrac{D}{T}}\,(&\parbox[m]{2cm}{\schemesarrow{$\unigoal{t_1}{t_2}$}{$Cs$}{$\schemewithvset{\mathfrak{S}}{U}$}} &)(\rho) &=& 1 +
      \sum\limits_{\substack{ \rho' \colon V \to \grterms \\
                                      \rho' \succ \rho \\
                                      \forall (y, t) \in Cs\,:\, \rho'\,(y) = t\, \rho'  }}
           \mathcal{\nicefrac{D}{T}}\,(\schemewithvset{\mathfrak{S}}{U})(\rho')  \\

 \mathcal{\nicefrac{D}{T}}\,(& \parbox[m]{4cm}{\schemedarrow{$\invokegoal{R^k}{t_1}{t_k}$}{ $(t_1, \dots, t_k) \in \sembr{R^k}  $}{$\schemewithvset{\mathfrak{S}}{U}$}} &)(\rho) &=&
      \nicefrac{d}{t}\,(\taskst{\invokegoal{R^k}{t_1 \rho}{t_k \rho}}{e_{init}}) +
      \sum\limits_{\substack{ \rho' \colon V \to \grterms \\
                                      \rho' \succ \rho \\
                                      (t_1 \rho', \dots, t_k \rho') \in \sembr{R^k}  }}
           \mathcal{\nicefrac{D}{T}}\,(\schemewithvset{\mathfrak{S}}{U})(\rho')  \\

 \mathcal{\nicefrac{D}{T}}\,(&\parbox[m]{2.5cm}{\schemefork{$\schemewithvset{\mathfrak{S}_1}{V}$}{$\schemewithvset{\mathfrak{S}_2}{V}$}}&)(\rho) &=&
 \mathcal{\nicefrac{D}{T}}\,(\schemewithvset{\mathfrak{S}_1}{V})(\rho) + \mathcal{\nicefrac{D}{T}}\,(\schemewithvset{\mathfrak{S}_2}{V})(\rho)
\end{array}
\]
\caption{Complexity Measures Extraction: $\mathcal D$ and $\mathcal T$}
\label{fig:scheduling_extraction_d_t}
\end{figure}


\begin{figure}[t]
\[
\begin{array}{rclcl}
 \mathcal{L}\,(&\parbox[m]{1.3cm}{\schemenode{$\unigoal{t_2}{t_2}$}}&)(\rho) &=& \{\taskst{\unigoal{t_2}{t_2}}{e_{init}}\} \\

 \mathcal{L}\,(&\parbox[m]{2.5cm}{\schemenode{$\invokegoal{R^k}{t_1}{t_k}$}}&)(\rho) &=& \{\taskst{\invokegoal{R^k}{t_1 \rho}{t_k \rho}}{e_{init}}\} \\

 \mathcal{L}\,(&\parbox[m]{2cm}{\schemesarrow{$\unigoal{t_1}{t_2}$}{$Cs$}{$\schemewithvset{\mathfrak{S}}{U}$}} &)(\rho) &=&  \{\taskst{\unigoal{t_2}{t_2}}{e_{init}}\} \cup
      \bigcup\limits_{\substack{ \rho' \colon V \to \grterms \\
                                      \rho' \succ \rho \\
                                      \forall (y, t) \in Cs\,:\, \rho'\,(y) = t\, \rho'  }}
           \mathcal{L}\,(\schemewithvset{\mathfrak{S}}{U})(\rho')  \\

 \mathcal{L}\,(& \parbox[m]{4cm}{\schemedarrow{$\invokegoal{R^k}{t_1}{t_k}$}{ $(t_1, \dots, t_k) \in \sembr{R^k}  $}{$\schemewithvset{\mathfrak{S}}{U}$}} &)(\rho) &=&
      \{\taskst{\invokegoal{R^k}{t_1 \rho}{t_k \rho}}{e_{init}}\} \cup
      \bigcup\limits_{\substack{ \rho' \colon V \to \grterms \\
                                      \rho' \succ \rho \\
                                      (t_1 \rho', \dots, t_k \rho') \in \sembr{R^k}  }}
           \mathcal{L}\,(\schemewithvset{\mathfrak{S}}{U})(\rho')  \\

 \mathcal{L}\,(&\parbox[m]{2.5cm}{\schemefork{$\schemewithvset{\mathfrak{S}_1}{V}$}{$\schemewithvset{\mathfrak{S}_2}{V}$}}&)(\rho) &=&
 \mathcal{L}\,(\schemewithvset{\mathfrak{S}_1}{V})(\rho) \cup \mathcal{L}\,(\schemewithvset{\mathfrak{S}_2}{V})(\rho)
\end{array}
\]
\caption{Complexity Measures Extraction: $\mathcal L$}
\label{fig:scheduling_extraction_l}
\end{figure}

We prove the theorem only for goals in DNF.

\[
\begin{array}{lcl}
B_{nf} & = &  \unigoal{\mathcal{T}_\mathcal{X}}{\mathcal{T}_\mathcal{X}} \; \mid \;
                     \invokegoal{R^k}{\mathcal{T}_\mathcal{X}}{\mathcal{T}_\mathcal{X}} \\
C_{nf} & = & B_{nf} \; \mid \; \conjgoal{C_{nf}}{B_{nf}} \\
F_{nf} & = & C_{nf} \; \mid \; \freshgoal{X}{F_{nf} } \\
D_{nf} & = & F_{nf} \; \mid \; \disjgoal{D_{nf}}{F_{nf}}
\end{array}
\]

We also have a requirement that all recursive calls performed during unification are \emph{grounding} and \emph{non-repetitive}.

\begin{definition}
  We call relational invocation
  
  \[\taskst{\invokegoal{R^k}{t_1}{t_k}}{e}\]

  \emph{grounding} and \emph{non-repetitive} if 

  \[ \forall (\sigma^{a}, n^{a}) \in \tra{\taskst{\invokegoal{R^k}{t_1}{t_k}}{e}} \,:\, FV(t_i \sigma^{a}) = \emptyset \]

  and
  
  \[ \forall (\sigma_1^{a},\, n_1^{a}),\, (\sigma_2^{a},\, n_2^{a}) \in \tra{\taskst{\invokegoal{R^k}{t_1}{t_k}}{e}} \,:\, (t_1 \sigma_1^{a}, \dots, t_k \sigma_1^{a}) \ne (t_1 \sigma_2^{a},\, \dots, t_k \sigma_2^{a}) \]
\end{definition}

The following main theorem provides the principal recursive approximations, extracted from the scheme for a given goal.

\begin{reptheorem}{extracted_approximations}
Let $g \in D_{nf}$ and all sub-calls encountered during its evaluation are grounding and non-repetitive, and let

\[  \schemetrans{g}{\epsilon}{\varepsilon}{n_{init}(g)}{V}{\schemewithvset{\mathfrak{S}}{V}}  \]

\noindent Then
\[
\begin{array}{rcl}
    d\,(init\,(g\,\rho)) &=& \mathcal{D}\,(\schemewithvset{\mathfrak{S}}{V})(\rho) + \Theta\,(1) \\
   t\,(init\,(g\,\rho)) &=& \mathcal{T}\,(\schemewithvset{\mathfrak{S}}{V})(\rho) + \Theta\,(\mathcal{D}\,(\schemewithvset{\mathfrak{S}}{V})(\rho)
   - \maxd\limits_{\taskst{g_i}{e_i} \in \mathcal{L}(\schemewithvset{\mathfrak{S}}{V})(\rho)} d\,(\taskst{g_i}{e_i}) + 1)
\end{array}
   \]
  being considered as functions on

  \[\rho \colon V \to T_{\emptyset}\]
\end{reptheorem}

It is based on the following fact as well as \lemmaword~\ref{lem:sum_estimation}, generalization of the \lemmaword~\ref{lem:times_measure_equations} and soundness and completeness of operational semantics w.r.t. the denotational one.

\begin{replemma}{lem:symbolic_unification_soundness}

  Let $t_1$, $t_2$ be terms,  $V \subset \mathcal{A}$ and $\rho \colon V \to \grterms$. If

  \[ mgu\,(t_1, t_2) = \delta \]

  and

  \[ U = \upd{V}{\delta} \]

  then $t_1 \rho$ and $t_2 \rho$ are unifiable iff there is some $\rho' \colon U \to \grterms$ such that $\rho' \succ \rho$ and $\forall (y, \, t) \in \constr{\delta}{U}\,:\, \rho'\,(y) = t \rho'$.
In such case $\rho'$ is unique and $ \rho \circ mgu\,(t_1 \rho, t_2 \rho) = \delta\circ\rho' $ up to alpha-equivalence (e.g. there exists a permutation $\pi$ on $FV(t_1) \cup FV(t_2)$, s.t. $ \rho \circ mgu\,(t_1 \rho, t_2 \rho) = \delta \circ\rho'\circ \pi$).
\end{replemma}

\subsection{Example}

To make it more clear we will demonatrate our approach on a specific example~--- analyzing a list reversing relation. The definition is given in \figureword~\ref{fig:reverso_definition}. It is a straightforward declarative definition that reverses the tail of the list and then make use of the separate \lstinline|append$^o$| relation to place the head of the list at the end.\footnote{As usual there is a more efficient tail-recursive version of the reverse relation. But we will go with the naive version here as it is more illustrative and the analysis will help us to understand just how inefficient the naive version is.}

\begin{figure}[t]
\begin{tabular}{p{6cm}p{6cm}}
\begin{lstlisting}[basicstyle=\small]
   revers$^o$ = fun a r ->
     ((a === Nil) /\ (r === Nil)) \/
     (fresh (h t tr)
        (a === Cons(h, t)) /\
        (revers$^o$ t tr) /\
        (append$^o$ tr Cons(h, Nil) r)
     )
\end{lstlisting} &
\begin{lstlisting}[basicstyle=\small]
   append$^o$ = fun a b ab ->
     ((a === Nil) /\ (ab === b)) \/
     (fresh (h t tb)
        (a === Cons(h, t)) /\
        (ab === Cons(h, tb)) /\
        (append$^o$ t b tb)
     )
\end{lstlisting}
\end{tabular}

\caption{Relational List Reverse Defintion}
\label{fig:reverso_definition}
\end{figure}

We will study the situation when we provide some ground term as a first argument and a free logical variable as a second argument. So our task is to estimate time measures for the base state \[ q^{rev}(\mathbf{a}) = init\,(\texttt{revers$^o$} \, \mathbf{a} \, r^?) \] depending on ground value $\mathbf{a}$. Also, we are usually intrested in situation when arguments are taken from some specific domain. In our case the domain is the set of all ground terms that are lists constructed with constructors $Nil$ and $Cons$.

\[ \mathcal{L} = Nil \; \mid \; Cons(D, \mathcal{L}) \]

We start our analysis by deriving a symbolic scheme for this call. To do it, we build the scheme for the goal $\texttt{revers$^o$} \, a^? \, r^?$ and take $\{ a^? \}$ as the set of ground variables $V$. The scheme is shown in \figureword~\ref{fig:reverso_scheme}.

\begin{figure}[t]
\begin{center}
\begin{tikzpicture}[sibling distance=10em, edge from parent/.style={draw,-latex}]
   \coordinate   
      child { node[rectangle, draw] {$\unigoal{\overline{a}}{\texttt{Nil}}$}
        child { node[rectangle, draw] {$\unigoal{r^?}{\texttt{Nil}}$}
                  edge from parent node[right]{\tiny{$\overline{a} = \texttt{Nil}$}} } }
      child { node[rectangle, draw] {$\unigoal{\overline{a}}{\texttt{Cons($h^?$, $t^?$)}}$} 
      	child { node[rectangle, draw] {\texttt{revers$^o$ $\overline{t}$ $tr^?$} }
      	   child { node[rectangle, draw] {\texttt{append$^o$ $\overline{tr}$ Cons($\overline{h}$, Nil) $r^?$}}
      	     edge from parent node[right]{\tiny{$(\overline{t}, \overline{tr}) \in \llbracket \texttt{revers$^o$} \rrbracket$}} }
      	   edge from parent node[right]{\tiny{$\overline{a} = \texttt{Cons($\overline{h}$, $\overline{t}$)}$}}  } } ;
\end{tikzpicture}
\end{center}

\caption{Symbolic execution scheme for the goal $\texttt{revers$^o$} \, a^? \, r^?$ with initial $V = \{ a^? \}$. Variables from the set of ground variables $V$ for each node are overlined (on edges variables are overlined in accordance with $V$ for the next node). }
\label{fig:reverso_scheme}
\end{figure}


We can see that the scheme contain two relational calls: a version of the same relational call $q^{rev}$ and another relational call \[ q^{app}(\mathbf{a}, \mathbf{b}) = init\,( \texttt{append$^o$} \, \mathbf{a} \, \mathbf{b} \, r^? ) \]

The traversing extracts the following recursive approximations for both measures from the scheme. Instead of passing mapping $\rho$ through the approximation, we will write it down as a dependency on ground value $\mathbf{a}$, as $\rho$ is defined by the value on the single element of $V$. We do the same for all mappings in the approximation.

\[
\begin{array}{lcll}
d(q^{rev}(\mathbf{a})) & = & & (1 + \sum\limits_{\mathbf{a} = \texttt{Nil}} 1) + \\
 & & & + \sum\limits_{\mathbf{h}, \mathbf{t}: \mathbf{a} = \texttt{Cons($\mathbf{h}$, $\mathbf{t}$)}} ( d(q^{rev}(\mathbf{t})) + \sum\limits_{\mathbf{tr}: (\mathbf{t}, \mathbf{tr}) \in \llbracket \texttt{revers$^o$} \rrbracket} d(q^{app}(\mathbf{tr},\texttt{Cons($\mathbf{h}$, Nil)}))) + \\
 & & + \Theta( & 1) \\
\\
t(q^{rev}(\mathbf{a})) & = & & (1 + \sum\limits_{\mathbf{a} = \texttt{Nil}} 1) + \\
 & & & \sum\limits_{\mathbf{h}, \mathbf{t}: \mathbf{a} = \texttt{Cons($\mathbf{h}$, $\mathbf{t}$)}} ( t(q^{rev}(\mathbf{t})) + \sum\limits_{\mathbf{tr}: (\mathbf{t}, \mathbf{tr}) \in \llbracket \texttt{revers$^o$} \rrbracket} t(q^{app}(\mathbf{tr},\texttt{Cons($\mathbf{h}$, Nil)}))) + \\
 & & + \Theta( & (1 + \sum\limits_{\mathbf{a} = \texttt{Nil}} 1) + \\
 & & & + \sum\limits_{\mathbf{h}, \mathbf{t}: \mathbf{a} = \texttt{Cons($\mathbf{h}$, $\mathbf{t}$)}} ( d(q^{rev}(\mathbf{t})) + \sum\limits_{\mathbf{tr}: (\mathbf{t}, \mathbf{tr}) \in \llbracket \texttt{revers$^o$} \rrbracket} d(q^{app}(\mathbf{tr},\texttt{Cons($\mathbf{h}$, Nil)}))) - \\
 & & & - \maxd\limits_{\mathbf{h}, \mathbf{t}, \mathbf{tr}: \mathbf{a} = \texttt{Cons($\mathbf{h}$, $\mathbf{t}$)} \land (\mathbf{t}, \mathbf{tr}) \in \llbracket \texttt{revers$^o$} \rrbracket} d(q^{app}(\mathbf{tr},\texttt{Cons($\mathbf{h}$, Nil)})) + 1)
\end{array}
\]

To make use of our approximations we need to analyze $q^{app}$ call separately. \figureword~\ref{fig:appendo_scheme} shows the symbolic scheme for this call. We extract the following approximations from it.

\[
\begin{array}{lcll}
d(q^{app}(\mathbf{a}, \mathbf{b})) & = & & (1 + \sum\limits_{\overline{a} = \texttt{Nil}} 1) + (1 + \sum\limits_{\mathbf{h}, \mathbf{t}: \mathbf{a} = \texttt{Cons($\mathbf{h}$, $\mathbf{t}$)}} (1 + d(q^{app}(\mathbf{t}, \mathbf{b})))) \\
& & + \Theta( & 1) \\
\\
t(q^{app}(\mathbf{a}, \mathbf{b})) & = & & (1 + \sum\limits_{\overline{a} = \texttt{Nil}} 1) + (1 + \sum\limits_{\mathbf{h}, \mathbf{t}: \mathbf{a} = \texttt{Cons($\mathbf{h}$, $\mathbf{t}$)}} (1 + t(q^{app}(\mathbf{t}, \mathbf{b})))) + \\
& & + \Theta( & (1 + \sum\limits_{\overline{a} = \texttt{Nil}} 1) + (1 + \sum\limits_{\mathbf{h}, \mathbf{t}: \mathbf{a} = \texttt{Cons($\mathbf{h}$, $\mathbf{t}$)}} (1 + d(q^{app}(\mathbf{t}, \mathbf{b})))) - \\
& & &  - \maxd\limits_{\mathbf{h}, \mathbf{t}: \mathbf{a} = \texttt{Cons($\mathbf{h}$, $\mathbf{t}$)}} d(q^{app}(\mathbf{t}, \mathbf{b})) + 1) 
\end{array}
\]

\begin{figure}[t]
\begin{center}
\begin{tikzpicture}[sibling distance=10em, edge from parent/.style={draw,-latex}]
   \coordinate   
      child { node[rectangle, draw] {$\unigoal{\overline{a}}{\texttt{Nil}}$}
        child { node[rectangle, draw] {$\unigoal{ab^?}{\overline{b}}$}
                  edge from parent node[right]{\tiny{$\overline{a} = \texttt{Nil}$}} } }
      child { node[rectangle, draw] {$\unigoal{\overline{a}}{\texttt{Cons($h^?$, $t^?$)}}$} 
      	child { node[rectangle, draw] {$\unigoal{ab^?}{\texttt{Cons($\overline{h}$, $tb^?$)}}$}
      	   child { node[rectangle, draw] {\texttt{append$^o$ $\overline{t}$ $\overline{b}$ $tb^?$}} }
      	   edge from parent node[right]{\tiny{$\overline{a} = \texttt{Cons($\overline{h}$, $\overline{t}$)}$}}  } } ;
\end{tikzpicture}
\end{center}

\caption{Symbolic execution scheme for the goal $\texttt{append$^o$} \, a^? \, b^? \, ab^?$ with initial $V = \{ a^?, b^? \}$. Variables from the set of ground variables $V$ for each node are overlined (on edges variables are overlined in accordance with $V$ for the next node). }
\label{fig:appendo_scheme}
\end{figure}

Now we move into the metatheory to solve this systems of recursive approximations and deduce the complexity. As usual, when we add the informations from the metatheory the approximations became quite simple.

For $q^{app}$ we consider two cases: when the first list is empty or not. Also, since there is only one non-trivial leaf in the scheme with only one enviroment, so we know that the excluded maximum is reached at the recursive call. After we exclude the recursive call from costs part, we get the following linear approximations. 

\[
\begin{array}{lcl}
d(q^{app}(\texttt{Nil}, \mathbf{b})) & = & \Theta(1) \\
d(q^{app}(\texttt{Cons($\mathbf{h}$, $\mathbf{t}$)}, \mathbf{b})) & = & d(q^{app}(\mathbf{t}, \mathbf{b})) + \Theta(1) \\
\\
t(q^{app}(\texttt{Nil}, \mathbf{b})) & = & \Theta(1) \\
t(q^{app}(\texttt{Cons($\mathbf{h}$, $\mathbf{t}$)}, \mathbf{b})) & = & t(q^{app}(\mathbf{t}, \mathbf{b})) + \Theta(1) \\
\end{array}
 \]
 
In this case the interleaving does not add a significant penalty, because we have recursive call in the end and its cost is eliminated. From these approximation it is clear that the complexity of both measures is linear on the length of the first argument.

\[
\begin{array}{lcl}
d(q^{app}(\mathbf{a}, \mathbf{b})) & = & \Theta(len(\mathbf{a})) \\
t(q^{app}(\mathbf{a}, \mathbf{b})) & = & \Theta(len(\mathbf{a})) \\
\end{array}
 \]
 
For initial relational call $q^{rev}$ we do the same and incorporate just calculated complexities of $q^{app}$. The senior addend is obvious again, it is value for $q^{app}$ call, but this time we also have an additional value for recursive call $q^{rev}$ in the costs part.

\[
\begin{array}{lcl}
d(q^{rev}(\texttt{Nil})) & = & \Theta(1) \\
d(q^{rev}(\texttt{Cons($\mathbf{h}$, $\mathbf{t}$)})) & = & d(q^{rev}(\overline{t})) + d(q^{app}(rev(\mathbf{t}), \texttt{Cons($\mathbf{h}$, Nil)})) + \Theta(1) \\
\\
t(q^{rev}(\texttt{Nil})) & = & \Theta(1) \\
t(q^{rev}(\texttt{Cons($\mathbf{h}$, $\mathbf{t}$)})) & = & t(q^{rev}(\overline{t})) + t(q^{app}(rev(\mathbf{t}), \texttt{Cons($\mathbf{h}$, Nil)})) + \Theta(d(q^{rev}(\mathbf{t}))) \\
\end{array}
 \]
 
We can now substitute the calculated measures for $q^{app}$ call. Since will know them only up to a multiplicative constant, they move under $\Theta$.

\[
\begin{array}{lcl}
d(q^{rev}(\texttt{Nil})) & = & \Theta(1) \\
d(q^{rev}(\texttt{Cons($\mathbf{h}$, $\mathbf{t}$)})) & = & d(q^{rev}(\mathbf{t})) + \Theta(len(\mathbf{t})) \\
\\
t(q^{rev}(\texttt{Nil})) & = & \Theta(1) \\
t(q^{rev}(\texttt{Cons($\mathbf{h}$, $\mathbf{t}$)})) & = & t(q^{rev}(\mathbf{t})) + \Theta(len(\mathbf{t}) + d(q^{rev}(\mathbf{t}))) \\
\end{array}
 \]
 
These approximation are linear and easily solvable, but in this case the additional cost of interleaving search is not negligible and the resulting complexity is not the same as the $d$ mesure.\footnote{Unlike the tail-recursive version of reverse where both measures have linear complexity.}
 
 \[
\begin{array}{lcl}
d(q^{rev}(\mathbf{a})) & = & \Theta(len^2(\mathbf{a})) \\
t(q^{rev}(\mathbf{a})) & = & \Theta(len^3(\mathbf{a})) \\
\end{array}
 \]

