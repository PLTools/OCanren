\section{Scheduling Complexity}
\label{sec:scheduling}

%In this section we define a specific value to estimate the scheduling time and derive some equations to calculate this value for a given \emph{semantic
%state}. However, our ultimate goal is to provide a complexity estimation for a given goal. This problem will be addressed in Section~\ref{sec:symbolic},
%in which we will make use of recurrent equations presented here.

We may notice that the operational semantics described in the previous section can be used to calculate the exact number of elementary scheduling steps.
Our first idea is to take the number of states $d\,(s)$ in the finite trace for a given state $s$:

\[ d\,(s) \; \eqdef \; | \trs{s} |  \]

However, it turns out that this value alone does not provide an accurate scheduling complexity estimation. The reason is that some
elementary steps in the semantics are not elementary in existing implementations. Namely, a careful analysis discovers that
each semantic step involves navigation to the leftmost leaf of the state which in implementations corresponds to multiple elementary actions,
whose number is proportional to the height of the leftmost branch of the state in question. Here we provide an \emph{ad-hoc} definition for this value, $t\,(s)$,
which we call the \emph{scheduling factor}:

\[
t\,(s) \eqdef \sum\limits_{s_i \in \trs{s}} lh\,(s_i) 
\]

where $lh\,(s_i)$ is the height of the leftmost branch of the state. 

\begin{comment}
\[
\begin{array}{rcl}
 lh\,(\taskst{g}{e})  &\eqdef& 1 \\
 lh\,(s_1 \oplus s_2) &\eqdef& lh\,(s_1) + 1 \\
 lh\,(s \otimes g)    &\eqdef& lh\,(s) + 1 \\
\end{array}
\]
\end{comment}


\begin{comment}
In the rest of the section, we state a number of lemmas providing estimations for these two values. The proofs for the lemmas (when omitted) can be
found in Appendix~\ref{sec:appendix}.

The first lemma provides a fundamental relation between these two~--- $d$ and $t$,~--- estimations for the scheduling complexity:

\begin{lemma}
\label{lem:d_t_relation}
 $d\,(s) \le t\,(s) \le d^2\,(s)$ for any state $s$.
\end{lemma} }
{ \color{red}
\begin{proof}
  Follows immediately from the definitions of the estimated values and the fact that the height of a state increases by at most $1$ at each step.\qed
\end{proof}
}
\end{comment}

In the rest of the section, we derive recurrent equations which would relate the scheduling complexity for states to the scheduling complexity for their
(immediate) substates. It turns out that to come up with such equations both $t$ and $d$ values have to be estimated simultaneously.  


% We take scheduling factor $t\,(s)$ as a value that determines the scheduling complexity $T_s$, but we will also need to calculate $d\,(s)$ as it will be used in the equations for $t\,(s)$. 

%In $\oplus$-states the substates are evaluated separately, one step at a time for each substate,
%so the total number of semantic steps is just a sum.
%However, for the scheduling factor, there is an extra summand since the heights of the states in
%the trace becomes bigger (by one additional $\oplus$-node on the top).
%This additional node exists in the trace until one of the substates is evaluated completely, so the
%scheduling factor is increased by the number of steps before such an event.
%So we have the following lemma.

The next lemma provides the equations for $\oplus$-states:

\begin{replemma}{lem:sum_measure_equations}
For any two states $s_1$ and $s_2$

\[
\begin{array}{rcl}
  d\,(s_1 \oplus s_2) &=& d\,(s_1) + d\,(s_2) \\
    t\,(s_1 \oplus s_2) &=& t\,(s_1) + t\,(s_2) + \costdisj{s_1}{s_2}
\end{array}
\]

where $\costdisj{s_1}{s_2} = \min\,\{2\cdot d\,(s_1) - 1, 2\cdot d\,(s_2)\}$
\end{replemma}

Informally, for a state in the form $s_1 \oplus s_2$ the substates are evaluated separately, one step at a time for
each substate, so the total number of semantic steps is the sum of those for the substates. However, for the scheduling factor, 
there is an extra summand $\costdisj{s_1}{s_2}$ since the ``leftmost heights'' of the states in the trace are one node greater than those for the
original substates due to the introduction of one additional $\oplus$-node on the top. This additional node persists in the trace until the evaluation
of one of the substates comes to an end, so the scheduling factor is increased by the number of steps until that.

The next lemma provides the equations for $\otimes$-states:\footnote{We assume $\Diamond\otimes g = \Diamond$}

\begin{replemma}{lem:times_measure_equations}
  For any state $s$ and any goal $g$
  
\[
\begin{array}{rclr}
d\,(s \otimes g)  &=&  d\,(s) + \smashoperator[lr]{\sum\limits_{a_i \in \tra{s}}} d\,(\taskst{g}{a_i})& \qquad(\star) \\

 t\,(s \otimes g)  &=&  t\,(s) + \costconj{s}{g} + \smashoperator[lr]{\sum\limits_{a_i \in \tra{s}}} (t\,(\taskst{g}{a_i}) + \costdisj{\taskst{g}{a_i}}{(s'_i \otimes g)})&\qquad(\dagger)
\end{array}
\]

where 
\[
\begin{array}{rcl}
\costconj{s}{g} & = & d\,(s) \\
s'_i & = & \mbox{the first state in the trace for $s$ after} \\
 & & \mbox{a transition delivering the answer $a_i$} \\
\end{array}
\]
\end{replemma}

For the states of the form $s \otimes g$ the reasoning is the same, but the resulting equations are more complicated.
In an $\otimes$-state the left substate is evaluated until an answer is found, which is then taken as
\emph{an environment} for the evaluation of the right subgoal.
Thus, in the equations for $\otimes$-states the evaluation times of the second goal \emph{for all
the answers} generated for the first substate are summed up. The evaluation of the right subgoal
in different environments is added to the evaluation of the left substate via creation of
an $\oplus$-state, so for the scheduling factor there is
an additional summand $\costdisj{\taskst{g}{a_i}}{s'_i}$ for each answer with $s'_i$ being the state
after discovering the answer.
There is also an extra summand $\costconj{s}{g}$ for the scheduling factor because of the
$\otimes$-node that increases the height in the trace, analogous to the one caused by
$\oplus$-nodes.
Note, a $\otimes$-node is always placed immediately over the left substate so this
addition is exactly the number of steps for the left substate.

Unfolding costs definitions in $(\dagger)$ gives us a cumbersome formula that 
includes some intermediate states $s'_i$ encountered during the evaluation. However, as ultimately
we are interested in asymptotic estimations, we can approximate these costs up to a multiplicative constant. We can notice that the value $d\,(s'_i \otimes g)$ occurring in the second argument of $cost_{\oplus}$ includes values $d\,(\taskst{g}{a_j})$ (like in the first argument) for all answers $a_j$ after this intermediate state. So in the sum of all $cost_{\oplus}$ values $d\,(\taskst{g}{a_i})$ may be excluded for at most one answer, and in fact, if we take the maximal one of these values we will get a rather precise approximation. Specifically, we can state the following approximation\footnote{We assume the following definition for
$f\,(x) = g\,(x) + \Theta\,(h\,(x))$: \[\exists C_1, C_2 \in \mathcal{R^{+}}, \, \forall x : g\,(x) + C_1 \cdot h\,(x) \le f\,(x) \le g\,(x) + C_2 \cdot h\,(x) \]}
for $t\,(s \otimes g)$.

\begin{replemma}{lem:otimes_t_approximation}
\[
 t\,(s \otimes g)  =  t\,(s) + \left({\sum\limits_{a_i \in \tra{s}}} t\,(\taskst{g}{a_i})\right) +
 \Theta\,(d\,(s) + \smashoperator[lr]{\sum\limits_{a_i \in \tra{s}}} d\,(\taskst{g}{a_i}) - \smashoperator{\maxd\limits_{a_i \in \tra{s}}} d\,(\taskst{g}{a_i}))	
\]
\end{replemma}

Hereafter we use the following notation: $\displaystyle{\maxd}\, S = \max\,(S\cup\{0\})$.
We can see that the part under $\Theta$ is very similar to the $(\star)$ except that here we exclude $d$ value for one of the answers from the sum.
This difference is essential and, as we will see later, it is in fact responsible for the difference in complexities for our motivating example.
 

